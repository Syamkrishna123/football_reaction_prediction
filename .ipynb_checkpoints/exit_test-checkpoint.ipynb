{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbdfa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e75c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath= os.listdir('C:/Users/syamk/OneDrive/Documents/exit test video/train')\n",
    "label= os.listdir('C:/Users/syamk/OneDrive/Documents/exit test video/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f79b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goal moments', 'happy moments', 'sad moments']\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6125c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tag                                              video\n",
      "0  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "1  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "2  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "3  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "4  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "            tag                                              video\n",
      "30  sad moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "31  sad moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "32  sad moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "33  sad moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "34  sad moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n"
     ]
    }
   ],
   "source": [
    "rooms= []\n",
    "for item in datapath:\n",
    "    all_rooms=os.listdir('C:/Users/syamk/OneDrive/Documents/exit test video/train'+ \"/\" +item)\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item,str('C:/Users/syamk/OneDrive/Documents/exit test video/train'+ '/' +item)+'/'+room))\n",
    "#Build a dataframe\n",
    "train_df= pd.DataFrame(data= rooms, columns=['tag','video'])\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eeebee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.loc[:,['video','tag']]\n",
    "df\n",
    "df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016c05a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goal moments', 'happy moments', 'sad moments']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.listdir(r'C:\\Users\\syamk\\OneDrive\\Documents\\exit test video\\test')\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e67f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of activities found:  3\n"
     ]
    }
   ],
   "source": [
    "room_types = os.listdir(r'C:\\Users\\syamk\\OneDrive\\Documents\\exit test video\\test')\n",
    "print(\"Types of activities found: \", len(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24eef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_rooms = os.listdir(r'C:\\Users\\syamk\\OneDrive\\Documents\\exit test video\\test' + '/' +item)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_rooms:\n",
    "    rooms.append((item, str(r'C:\\Users\\syamk\\OneDrive\\Documents\\exit test video\\test' + '/' +item) + '/' + room))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb5010a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tag                                              video\n",
      "0  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "1  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "2  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "3  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "4  goal moments  C:/Users/syamk/OneDrive/Documents/exit test vi...\n",
      "            tag                                              video\n",
      "53  sad moments  C:\\Users\\syamk\\OneDrive\\Documents\\exit test vi...\n",
      "54  sad moments  C:\\Users\\syamk\\OneDrive\\Documents\\exit test vi...\n",
      "55  sad moments  C:\\Users\\syamk\\OneDrive\\Documents\\exit test vi...\n",
      "56  sad moments  C:\\Users\\syamk\\OneDrive\\Documents\\exit test vi...\n",
      "57  sad moments  C:\\Users\\syamk\\OneDrive\\Documents\\exit test vi...\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame(data=rooms, columns=['tag', 'video'])\n",
    "print(test_df.head())\n",
    "print(test_df.tail())\n",
    "\n",
    "df = test_df.loc[:,['video','tag']]\n",
    "df\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99901e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c962dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\syamk\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb7e097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd96b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 35\n",
      "Total videos for testing: 58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>goal moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>happy moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>sad moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>goal moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>goal moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>sad moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>sad moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>happy moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>happy moments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>C:/Users/syamk/OneDrive/Documents/exit test vi...</td>\n",
       "      <td>sad moments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                              video  \\\n",
       "8            8  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "20          20  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "29          29  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "2            2  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "0            0  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "30          30  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "23          23  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "22          22  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "15          15  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "33          33  C:/Users/syamk/OneDrive/Documents/exit test vi...   \n",
       "\n",
       "              tag  \n",
       "8    goal moments  \n",
       "20  happy moments  \n",
       "29    sad moments  \n",
       "2    goal moments  \n",
       "0    goal moments  \n",
       "30    sad moments  \n",
       "23    sad moments  \n",
       "22  happy moments  \n",
       "15  happy moments  \n",
       "33    sad moments  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0405ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e3fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d0c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goal moments', 'happy moments', 'sad moments']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5be3a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea8b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features in train set: (35, 20, 2048)\n",
      "Frame masks in train set: (35, 20)\n",
      "train_labels in train set: (35, 1)\n",
      "test_labels in train set: (58, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video\"].values.tolist()\n",
    "    \n",
    "    ##take all classlabels from train_df column named 'tag' and store in labels\n",
    "    labels = df[\"tag\"].values\n",
    "    \n",
    "    #convert classlabels to label encoding\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
    "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"train_labels in train set: {train_labels.shape}\")\n",
    "\n",
    "print(f\"test_labels in train set: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8091ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1259 - accuracy: 0.2917\n",
      "Epoch 1: val_loss improved from inf to 1.76587, saving model to ./tmp\\video_classifier\n",
      "1/1 [==============================] - 12s 12s/step - loss: 1.1259 - accuracy: 0.2917 - val_loss: 1.7659 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9726 - accuracy: 0.5000\n",
      "Epoch 2: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9726 - accuracy: 0.5000 - val_loss: 1.8439 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.5833\n",
      "Epoch 3: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8525 - accuracy: 0.5833 - val_loss: 2.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8425 - accuracy: 0.6667\n",
      "Epoch 4: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8425 - accuracy: 0.6667 - val_loss: 2.1029 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8500 - accuracy: 0.6250\n",
      "Epoch 5: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8500 - accuracy: 0.6250 - val_loss: 2.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8496 - accuracy: 0.5833\n",
      "Epoch 6: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8496 - accuracy: 0.5833 - val_loss: 2.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7874 - accuracy: 0.6250\n",
      "Epoch 7: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7874 - accuracy: 0.6250 - val_loss: 2.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7856 - accuracy: 0.5000\n",
      "Epoch 8: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7856 - accuracy: 0.5000 - val_loss: 2.0431 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.7500\n",
      "Epoch 9: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7222 - accuracy: 0.7500 - val_loss: 2.0531 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7826 - accuracy: 0.6250\n",
      "Epoch 10: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7826 - accuracy: 0.6250 - val_loss: 2.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7817 - accuracy: 0.8333\n",
      "Epoch 11: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7817 - accuracy: 0.8333 - val_loss: 1.9516 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.7917\n",
      "Epoch 12: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7238 - accuracy: 0.7917 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.7500\n",
      "Epoch 13: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6544 - accuracy: 0.7500 - val_loss: 1.9499 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7704 - accuracy: 0.7083\n",
      "Epoch 14: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7704 - accuracy: 0.7083 - val_loss: 1.9701 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6736 - accuracy: 0.9167\n",
      "Epoch 15: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6736 - accuracy: 0.9167 - val_loss: 2.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.8333\n",
      "Epoch 16: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6953 - accuracy: 0.8333 - val_loss: 2.0653 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.7917\n",
      "Epoch 17: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6591 - accuracy: 0.7917 - val_loss: 2.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.8750\n",
      "Epoch 18: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6744 - accuracy: 0.8750 - val_loss: 2.1436 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7578 - accuracy: 0.7500\n",
      "Epoch 19: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7578 - accuracy: 0.7500 - val_loss: 2.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.7917\n",
      "Epoch 20: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6673 - accuracy: 0.7917 - val_loss: 2.0831 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 1.0000\n",
      "Epoch 21: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6405 - accuracy: 1.0000 - val_loss: 2.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.8750\n",
      "Epoch 22: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6908 - accuracy: 0.8750 - val_loss: 2.0873 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.8750\n",
      "Epoch 23: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6236 - accuracy: 0.8750 - val_loss: 2.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.7917\n",
      "Epoch 24: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6553 - accuracy: 0.7917 - val_loss: 2.1024 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6682 - accuracy: 0.8750\n",
      "Epoch 25: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6682 - accuracy: 0.8750 - val_loss: 2.1127 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.8750\n",
      "Epoch 26: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6052 - accuracy: 0.8750 - val_loss: 2.1239 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.8750\n",
      "Epoch 27: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5787 - accuracy: 0.8750 - val_loss: 2.1196 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.9167\n",
      "Epoch 28: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5618 - accuracy: 0.9167 - val_loss: 2.1014 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.8333\n",
      "Epoch 29: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5632 - accuracy: 0.8333 - val_loss: 2.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.7917\n",
      "Epoch 30: val_loss did not improve from 1.76587\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5731 - accuracy: 0.7917 - val_loss: 2.0460 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 1.1221 - accuracy: 0.3103\n",
      "Test accuracy: 31.03%\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Utility for our sequence model.\n",
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "EPOCHS = 30\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"./tmp/video_classifier\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e1625f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: C:/Users/syamk/OneDrive/Documents/exit test video/train/sad moments/sad moment4.mp4\n",
      "  happy moments: 42.28%\n",
      "  goal moments: 40.00%\n",
      "  sad moments: 17.71%\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "\n",
    "test_frames = sequence_prediction(test_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c973c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
